{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":72549,"databundleVersionId":7959527,"sourceType":"competition"},{"sourceId":7860796,"sourceType":"datasetVersion","datasetId":4611218}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-16T19:46:00.260590Z","iopub.execute_input":"2024-03-16T19:46:00.260895Z","iopub.status.idle":"2024-03-16T19:46:00.266548Z","shell.execute_reply.started":"2024-03-16T19:46:00.260872Z","shell.execute_reply":"2024-03-16T19:46:00.265897Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/ai-for-social-good-aries-iitd-x-kaizen-24/Public/Task 1/train.csv\")\n# train_data = pd.read_csv(\"/kaggle/input/customdataset/DataSet.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/ai-for-social-good-aries-iitd-x-kaizen-24/Public/Task 1/test.csv\")\n# print(train_data.head())","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:46:00.267611Z","iopub.execute_input":"2024-03-16T19:46:00.267810Z","iopub.status.idle":"2024-03-16T19:46:00.304730Z","shell.execute_reply.started":"2024-03-16T19:46:00.267792Z","shell.execute_reply":"2024-03-16T19:46:00.303862Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# Tokenize text data\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(train_data['tweet_text'])\nX = tokenizer.texts_to_sequences(train_data['tweet_text'])\nX = pad_sequences(X, maxlen=100) # Assuming a maximum sequence length of 100\ny = train_data['claim']","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:46:00.307648Z","iopub.execute_input":"2024-03-16T19:46:00.307896Z","iopub.status.idle":"2024-03-16T19:46:00.765337Z","shell.execute_reply.started":"2024-03-16T19:46:00.307875Z","shell.execute_reply":"2024-03-16T19:46:00.764539Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"model = Sequential([\n    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100),\n    Bidirectional(LSTM(64)),\n    Dense(1, activation='sigmoid')\n])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\nmodel.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:46:00.766240Z","iopub.execute_input":"2024-03-16T19:46:00.766484Z","iopub.status.idle":"2024-03-16T19:46:53.314182Z","shell.execute_reply.started":"2024-03-16T19:46:00.766462Z","shell.execute_reply":"2024-03-16T19:46:53.313544Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8768 - loss: 0.4035 - val_accuracy: 0.8791 - val_loss: 0.3465\nEpoch 2/5\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.8788 - loss: 0.2843 - val_accuracy: 0.8705 - val_loss: 0.3737\nEpoch 3/5\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.9525 - loss: 0.1302 - val_accuracy: 0.8062 - val_loss: 0.5109\nEpoch 4/5\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.9817 - loss: 0.0530 - val_accuracy: 0.8162 - val_loss: 0.6428\nEpoch 5/5\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.9933 - loss: 0.0246 - val_accuracy: 0.8262 - val_loss: 0.6034\n","output_type":"stream"},{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7bf630294ee0>"},"metadata":{}}]},{"cell_type":"code","source":"# Predict probabilities\ny_pred_prob = model.predict(X_val)\n# Convert probabilities to binary predictions (0 or 1)\ny_pred = np.round(y_pred_prob).flatten()\n# Calculate accuracy\naccuracy = accuracy_score(y_val, y_pred)\nprint(\"Validation Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:46:53.315880Z","iopub.execute_input":"2024-03-16T19:46:53.316709Z","iopub.status.idle":"2024-03-16T19:46:54.632903Z","shell.execute_reply.started":"2024-03-16T19:46:53.316686Z","shell.execute_reply":"2024-03-16T19:46:54.631903Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\nValidation Accuracy: 0.8261802575107297\n","output_type":"stream"}]},{"cell_type":"code","source":"# Preprocess test data similarly to training data\nX_test = tokenizer.texts_to_sequences(test_data['tweet_text'])\nX_test = pad_sequences(X_test, maxlen=100)\n# Make predictions\ntest_predictions = model.predict(X_test)\n# Convert predictions to binary classes (0 or 1)\ntest_predictions = np.round(test_predictions).flatten()\n\n# Create a DataFrame with the predictions\nsubmission_df = pd.DataFrame({'claim': test_predictions})\n\n# Optionally, if your test data has an 'ID' column, you can include it in the submission DataFrame\nif 'ID' in test_data.columns:\n    submission_df['ID'] = test_data['ID']\n\n# Save predictions to a CSV file\nsubmission_df.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:46:54.633898Z","iopub.execute_input":"2024-03-16T19:46:54.634306Z","iopub.status.idle":"2024-03-16T19:46:55.355288Z","shell.execute_reply.started":"2024-03-16T19:46:54.634284Z","shell.execute_reply":"2024-03-16T19:46:55.354660Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"# Example single tweet text\nsingle_tweet_text = \"India's captail is Lahore\"\n\n# Preprocess the single tweet text\nsingle_tweet_sequence = tokenizer.texts_to_sequences([single_tweet_text])\nsingle_tweet_sequence = pad_sequences(single_tweet_sequence, maxlen=100) # Assuming the same maximum sequence length as training data\n\n# Make prediction\nprediction_prob = model.predict(single_tweet_sequence)\nprediction = np.round(prediction_prob).flatten()[0]\n\n# Interpret the prediction\nif prediction == 1:\n    print(\"The tweet contains a claim.\")\nelse:\n    print(\"The tweet does not contain a claim.\")","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:46:55.357165Z","iopub.execute_input":"2024-03-16T19:46:55.357530Z","iopub.status.idle":"2024-03-16T19:46:55.431683Z","shell.execute_reply.started":"2024-03-16T19:46:55.357494Z","shell.execute_reply":"2024-03-16T19:46:55.430850Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\nThe tweet does not contain a claim.\n","output_type":"stream"}]},{"cell_type":"code","source":"X_test = tokenizer.texts_to_sequences(test_data['tweet_text'])\nX_test = pad_sequences(X_test, maxlen=100)\n# Make predictions\ntest_predictions = model.predict(X_test)\n# Convert predictions to binary classes (0 or 1)\ntest_predictions = np.round(test_predictions).flatten()\n\n# Create a DataFrame with the predictions\nsubmission_df = pd.DataFrame({'claim': test_predictions})\n\n# Optionally, if your test data has an 'ID' column, you can include it in the submission DataFrame\nif 'ID' in test_data.columns:\n    submission_df['ID'] = test_data['ID']\n\n# Save predictions to a CSV file\nsubmission_df.to_csv('submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:46:55.432740Z","iopub.execute_input":"2024-03-16T19:46:55.433378Z","iopub.status.idle":"2024-03-16T19:46:56.159060Z","shell.execute_reply.started":"2024-03-16T19:46:55.433354Z","shell.execute_reply":"2024-03-16T19:46:56.158447Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n","output_type":"stream"}]}]}