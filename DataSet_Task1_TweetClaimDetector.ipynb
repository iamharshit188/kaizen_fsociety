{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n","train_data = pd.read_csv(\"/kaggle/input/ai-for-social-good-aries-iitd-x-kaizen-24/Public/Task 1/train.csv\")\n","# train_data = pd.read_csv(\"/kaggle/input/newdata/DataSet.csv\")\n","test_data = pd.read_csv(\"/kaggle/input/ai-for-social-good-aries-iitd-x-kaizen-24/Public/Task 1/test.csv\")\n","# print(train_data.head())\n","# Tokenize text data\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(train_data['tweet_text'])\n","X = tokenizer.texts_to_sequences(train_data['tweet_text'])\n","X = pad_sequences(X, maxlen=100) # Assuming a maximum sequence length of 100\n","y = train_data['claim']\n","model = Sequential([\n","    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100),\n","    Bidirectional(LSTM(64)),\n","    Dense(1, activation='sigmoid')\n","])\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n","# Predict probabilities\n","y_pred_prob = model.predict(X_val)\n","# Convert probabilities to binary predictions (0 or 1)\n","y_pred = np.round(y_pred_prob).flatten()\n","# Calculate accuracy\n","accuracy = accuracy_score(y_val, y_pred)\n","print(\"Validation Accuracy:\", accuracy)\n","# Preprocess test data similarly to training data\n","X_test = tokenizer.texts_to_sequences(test_data['tweet_text'])\n","X_test = pad_sequences(X_test, maxlen=100)\n","# Make predictions\n","test_predictions = model.predict(X_test)\n","# Convert predictions to binary classes (0 or 1)\n","test_predictions = np.round(test_predictions).flatten()\n","\n","# Create a DataFrame with the predictions\n","submission_df = pd.DataFrame({'claim': test_predictions})\n","\n","# Optionally, if your test data has an 'ID' column, you can include it in the submission DataFrame\n","if 'ID' in test_data.columns:\n","    submission_df['ID'] = test_data['ID']\n","\n","# Save predictions to a CSV file\n","submission_df.to_csv('submission.csv', index=False)\n","# Load dev data\n","dev_data = pd.read_csv(\"/kaggle/input/ai-for-social-good-aries-iitd-x-kaizen-24/Public/Task 1/dev.csv\")\n","\n","# Preprocess dev data\n","X_dev = tokenizer.texts_to_sequences(dev_data['tweet_text'])\n","X_dev = pad_sequences(X_dev, maxlen=100) # Assuming the same maximum sequence length as training data\n","y_dev = dev_data['claim']\n","\n","# Validate model on dev data\n","y_dev_pred_prob = model.predict(X_dev)\n","y_dev_pred = np.round(y_dev_pred_prob).flatten()\n","\n","# Calculate accuracy\n","dev_accuracy = accuracy_score(y_dev, y_dev_pred)\n","print(\"Validation Accuracy on dev set:\", dev_accuracy)\n","\n","# Preprocess test data similarly to training data\n","X_test = tokenizer.texts_to_sequences(test_data['tweet_text'])\n","X_test = pad_sequences(X_test, maxlen=100)\n","# Make predictions\n","test_predictions = model.predict(X_test)\n","# Convert predictions to binary classes (0 or 1)\n","test_predictions = np.round(test_predictions).flatten()\n","\n","# Create a DataFrame with the predictions\n","submission_df = pd.DataFrame({'claim': test_predictions})\n","\n","# Optionally, if your test data has an 'ID' column, you can include it in the submission DataFrame\n","if 'ID' in test_data.columns:\n","    submission_df['ID'] = test_data['ID']\n","\n","# Save predictions to a CSV file\n","submission_df.to_csv('submission.csv', index=False)\n","# Example single tweet text\n","single_tweet_text = \"The Earth is flat.\"\n","\n","# Preprocess the single tweet text\n","single_tweet_sequence = tokenizer.texts_to_sequences([single_tweet_text])\n","single_tweet_sequence = pad_sequences(single_tweet_sequence, maxlen=100) # Assuming the same maximum sequence length as training data\n","\n","# Make prediction\n","prediction_prob = model.predict(single_tweet_sequence)\n","prediction = np.round(prediction_prob).flatten()[0]\n","\n","# Interpret the prediction\n","if prediction == 1:\n","    print(\"The tweet contains a claim.\")\n","else:\n","    print(\"The tweet does not contain a claim.\")\n","    # Example single tweet text\n","single_tweet_text = \"History being checked! Tx for it ABjr. If it wasn't  RIGHT,it would have LEFT a bad taste\"\n","\n","# Preprocess the single tweet text\n","single_tweet_sequence = tokenizer.texts_to_sequences([single_tweet_text])\n","single_tweet_sequence = pad_sequences(single_tweet_sequence, maxlen=100) # Assuming the same maximum sequence length as training data\n","\n","# Make prediction\n","prediction_prob = model.predict(single_tweet_sequence)\n","prediction = np.round(prediction_prob).flatten()[0]\n","\n","# Interpret the prediction\n","if prediction == 1:\n","    print(\"The tweet contains a claim.\")\n","else:\n","    print(\"The tweet does not contain a claim.\")\n","    # Example single tweet text\n","single_tweet_text = \"The Earth is flat.\"\n","\n","# Preprocess the single tweet text\n","single_tweet_sequence = tokenizer.texts_to_sequences([single_tweet_text])\n","single_tweet_sequence = pad_sequences(single_tweet_sequence, maxlen=100) # Assuming the same maximum sequence length as training data\n","\n","# Make prediction\n","prediction_prob = model.predict(single_tweet_sequence)\n","prediction = np.round(prediction_prob).flatten()[0]\n","\n","# Interpret the prediction\n","if prediction == 1:\n","    print(\"The tweet contains a claim.\")\n","else:\n","    print(\"The tweet does not contain a claim.\")\n","\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":7959527,"sourceId":72549,"sourceType":"competition"},{"datasetId":4611218,"sourceId":7860796,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
